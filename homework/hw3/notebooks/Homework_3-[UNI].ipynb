{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "### Due: Nov 30th @ 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing \n",
    "\n",
    "- feature cleaning and engineering\n",
    "\n",
    "- dimensionality reduction and clustering\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the comments below and fill in the blanks (\\_\\_\\_\\_) to complete.\n",
    "\n",
    "Please 'Restart and Run All' prior to submission.\n",
    "\n",
    "Out of 67 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. (1pt) Set up our environment with comman libraries and plotting.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy, pandas, matplotlib.pyplot and seaborn\n",
    "____\n",
    "\n",
    "# Execute the matplotlib magic function to display plots inline\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will be loading, cleaning and transforming a small set of data related to loan applications.\n",
    "\n",
    "There are two files, one containing loan application information and the other containing borrower information.\n",
    "\n",
    "You will need to load both files, join them and then create a new dataframe with transformations of the data which could then be used for modelling.\n",
    "\n",
    "Each step is followed by a print or plot of some kind to help us catch errors as they happen instead of later in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts) Load Loan Application Data\n",
    "\n",
    "# Read in the first dataframe containing loan application information.\n",
    "# The path to the datafile is '../data/hw3_loan.csv'.\n",
    "# Use the appropriate pandas command to read a csv file.\n",
    "# 'CustomerID' is a unique id that should be set as the index using the index_col argument.\n",
    "# Store this dataframe as df_loan.\n",
    "____\n",
    "\n",
    "# Print the shape of df_loan (should be 633 rows, 4 columns)\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (2pts) Load Borrower Data\n",
    "\n",
    "# Read in the first dataframe containing borrower information.\n",
    "# The path to the datafile is '../data/hw3_borrower.csv'.\n",
    "# Use the appropriate pandas command to read a csv file.\n",
    "# 'CustomerID' is a unique id that should be set as the index using the index_col argument.\n",
    "# Store this dataframe as df_borrower.\n",
    "____\n",
    "\n",
    "# Print the shape of df_borrower (should be 633 rows, 2 columns)\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. (2pts) Join Datasets\n",
    "\n",
    "# Join the datasets and store as df.\n",
    "# Perform an inner join.\n",
    "# Note that since both dataframes share an index, it is easier to use the 'join' command.\n",
    "____\n",
    "\n",
    "# Print df information summary using 'info'\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (1pt) LoanReason\n",
    "\n",
    "# Loan reason is a categorical variable.\n",
    "# Print the counts of each category using 'value_counts'\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (2pts) Transform LoanReason Using One-Hot Encoding\n",
    "\n",
    "# Transform LoanReason into one-hot encoding using 'get_dummies'.\n",
    "# Use the columnname prefix 'LoanReason'.\n",
    "# Leave all other arguments at defaults.\n",
    "# Store resulting dataframe as df_loanreason\n",
    "____\n",
    "\n",
    "# Print the 'head' of df_loanreason to confirm the transformation.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (2pts) Create Transformed Feature Dataframe\n",
    "\n",
    "# We are performing these transformations in order to use this data for modelling.\n",
    "#\n",
    "# Instead of adding transformed features into our original dataframe\n",
    "#   it is useful to create a new dataframe containing only features used for modelling.\n",
    "\n",
    "# Create this new dataframe by copying df_loanreason into df_features using 'copy'.\n",
    "____\n",
    "\n",
    "# Print df_features information summary using 'info'\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (1pt) LoanPayoffPeriodInMonths\n",
    "\n",
    "# Use seaborn distplot to plot LoanPayoffPeriodInMonths using default settings.\n",
    "# Note that there appear to be several modes in the data corresponding to years.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. (2pts) Create Period Bins\n",
    "\n",
    "# We'll bin LoanPayoffPeriodInMonths into [less than 1 year, 1 to 2 years, more than 2 years]\n",
    "# Create a list with four values\n",
    "#   minimum value in LoanPayoffPeriodInMonths\n",
    "#   12\n",
    "#   24\n",
    "#   maximum value of LoanPayoffPeriodInMonths\n",
    "# Store this list as 'period_bins'\n",
    "____\n",
    "\n",
    "# Print period_bins.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (3pts) Bin LoanPayoffPeriodInMonths\n",
    "\n",
    "# Use 'pd.cut' to bin LoanPayoffPeriodInMonths.\n",
    "# Use the period_bins list we created above for the bin edges.\n",
    "# Set the bin labels as ['0','1','2+'].\n",
    "# Store as loanperiod_years\n",
    "____\n",
    "\n",
    "# loanperiod_years is a Series.\n",
    "# Print the number of items in each bin of loanperiod_years using 'value_counts'.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. (2pts) Transform Period Year Bins as One-Hot Encoding\n",
    "\n",
    "# Use 'pd.get_dummies' to encode loanperiod_years.\n",
    "# Use prefix 'LoanPeriodYears'.\n",
    "# Store as df_loanperiod.\n",
    "____\n",
    "\n",
    "# Print 'head' of df_loanperiod confirm the transformation.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. (2pts) Extend Transformed Features\n",
    "\n",
    "# Join the existing df_features dataframe with df_loanperiod.\n",
    "# Note that they share an index, so join is easy to use here.\n",
    "# Store the result back into df_features.\n",
    "____\n",
    "\n",
    "# Print df_features information summary using 'info'.\n",
    "# Note that the new columns have been joined.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. (1pt) RequestedAmount\n",
    "\n",
    "# Use seaborn distplot to plot RequestedAmount using default settings.\n",
    "# Note that this features is very skewed and has a very wide range.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. (2pts) Log Transform RequestedAmount\n",
    "\n",
    "# Using the 'apply' function, apply np.log to the RequestedAmount column.\n",
    "# Store the result as requestedamount_log\n",
    "____\n",
    "\n",
    "# Use seaborn distplot to plot the transformed variable using default settings.\n",
    "# Note that the shape is much more 'normal'.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. (3pts) Center and Scale log(RequestedAmount) Manually\n",
    "\n",
    "# Standardize requestedamount_log by subtracting the mean and dividing by the standard deviation.\n",
    "# Store the result into df_features as RequestedAmount_log_scaled\n",
    "____\n",
    "\n",
    "# Use seaborn distplot to plot RequestedAmount_log_scaled.\n",
    "# Note that data has been centered and scaled.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. (2pts) Age\n",
    "\n",
    "# The Age variable has missing values.\n",
    "# Before we fill the missing values, create a dummy column noting where data is missing.\n",
    "# We want to store this as an int instead of a boolean.\n",
    "# Use 'isnull().astype(int)' on the Age column to both find nulls and convert boolean to int.\n",
    "# Store in df_features as 'Age_missing'.\n",
    "____\n",
    "\n",
    "# Print the number of 0s and 1s in Age_missing using 'value_counts'.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. (2pts) Fill Age with Median\n",
    "\n",
    "# Age may be skewed so fill missing values using median instead of mean.\n",
    "# Use 'fillna' and 'median' to fill the missing values in Age with the median of Age.\n",
    "# Store back into df['Age']\n",
    "____\n",
    "\n",
    "# Use seaborn distplot to plot Age.\n",
    "# Note that we might want to transform this variable using log to remove skew \n",
    "#    but will not do so in this homework.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. (3pts) Center and Scale Age Using StandardScaler\n",
    "\n",
    "# Import StandardScaler from sklearn\n",
    "____\n",
    "\n",
    "# Using StandardScaler and fit_transform, standardize the Age columns.\n",
    "# Note that fit_transform expects a DataFrame not a Series.\n",
    "# Use df[['Age']] to return a DataFrame.\n",
    "# Store the result in df_features as 'Age_scaled'\n",
    "____\n",
    "\n",
    "# Print out the mean and standard deviation of Age_scaled.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. (1pt) YearsAtCurrentEmployer\n",
    "\n",
    "# There are missing values in YearsAtCurrentEmployer as well.\n",
    "# Since this is a categorical feature, we'll fill with the most common value (mode).\n",
    "# First, print the number of items in each category, including nan's\n",
    "#   using value_counts with dropna=False\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. (2pts) Get Mode of YearsAtCurrentEmployer\n",
    "\n",
    "# Pandas Series has a 'mode' function that returns another series containing the modes of the original series.\n",
    "# We just want the first value in that series.\n",
    "# Use '.mode().values[0]' to get the first value in the series returned by mode.\n",
    "# Store in years_mode\n",
    "____\n",
    "\n",
    "# Print the value found.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. (2pts) Fill Missing in YearsAtCurrentEmployer With Mode\n",
    "\n",
    "# Use fillna and years_mode to fill the missing values in the YearsAtCurrentEmployer column.\n",
    "# Store back into df.YearsAtCurrentEmployer\n",
    "____\n",
    "\n",
    "# Print the value_counts of YearsAtCurrentEmployer, again with dropna=False.\n",
    "# Note that there are no longer nan's.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. (2pts) One-Hot Encode YearsAtCurrentEmployer\n",
    "\n",
    "# Use 'pd.get_dummies' to encode YearsAtCurrentEmployer.\n",
    "# Use prefix 'YearsAtCurrentEmployer'.\n",
    "# Store as df_employed.\n",
    "____\n",
    "\n",
    "# Print 'head' of df_employed to confirm the transformation.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. (2pts) Extend Transformed Features with YearsAtCurrentEmployer\n",
    "\n",
    "# Join the existing df_features dataframe with df_employed.\n",
    "# Note that they share an index, so join is easy to use here.\n",
    "# Store the result back into df_features.\n",
    "____\n",
    "\n",
    "# Print df_features information summary using 'info'.\n",
    "# Note that the new columns have been joined, all datatypes are numeric and there are no missing values.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : PCA and K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST digits dataset is composed of a set of images of handwritten digits from 0 to 9.\n",
    "There are 1797 images, each 8x8 pixels.\n",
    "If we flatten out each image we get a dataset of 1797 observations, each with 64 features, each belonging to one of 10 classes.\n",
    "Here we'll reduce dimensionality to 2-D to see if the data clusters by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. (4pts) Load the Digits Dataset\n",
    "\n",
    "# This dataset loads as a dictionary.\n",
    "# For our purposes we need access to 3 things by key name:\n",
    "#   'images': a list of lists with images stored in their 8x8 form\n",
    "#   'data': a list of lists with images flattened in their 1x64 form\n",
    "#   'target': a list of category labels\n",
    "\n",
    "# From sklearn datasets import load_digits.\n",
    "____\n",
    "\n",
    "# Load the dataset into 'digits' using load_digits\n",
    "____\n",
    "\n",
    "# Extract digits['data'] to X_digits. No need to reshape.\n",
    "____\n",
    "\n",
    "# Extract the labels in digits['target'] to y_digits\n",
    "____\n",
    "\n",
    "# Print the shape of X_digits (should be 1797 rows, 64 columns).\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. (2pts) Plot the first image in digits['images'].\n",
    "\n",
    "# 'digits['images']' is a list of images of size 8x8 pixels.\n",
    "# Plot the first image using plt.imshow with cmap=plt.cm.gray_r, all other arguments as their default.\n",
    "# You should see a black '0' on a white background.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. (2pts) Import and Instantiate PCA\n",
    "\n",
    "# Import PCA from sklearn\n",
    "____\n",
    "\n",
    "# Instantiate a pca object that will result in 2 components being returned.\n",
    "# Use random_state=123, all other arguments as their default.\n",
    "# Store as 'pca'.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. (2pts) Transform X_digits Using PCA\n",
    "\n",
    "# Using pca created above, call fit_transform on X_digits to transform into 2-D.\n",
    "# Store as X_2D.\n",
    "____\n",
    "\n",
    "# Print the  shape of X_2D. Should be (1797,2)\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. (4pts) Plot PCA Representation Colored by Labels\n",
    "\n",
    "# In this example, we have labels for our dataset.\n",
    "# Create a plot visualizing X_2D as a scatterplot, colored by label.\n",
    "# We should see that classes are somewhat seperable, with some overlap.\n",
    "\n",
    "# Create a single figure and axis of size 8,8 using plt.subplots.\n",
    "____\n",
    "\n",
    "# For each category (0 to 9):\n",
    "for category in range(10):\n",
    "    # Select the rows from X_2D with that label using y_digit.\n",
    "    # Store as X_subset\n",
    "    ____\n",
    "    # Add a scatter plot of X_subset to the axis using ax.scatter()\n",
    "    #    with s=80 (size), alpha=0.8 (to make markers transparent) and label='digit' + str(category)\n",
    "    ____\n",
    "\n",
    "# Add a legend to the plot.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How clustered are our classes? Can k-Means find clusters in the 2D PCA transformed data that at all correspond to the plot seen above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. (2pts) Import and Instantiate KMeans\n",
    "\n",
    "# Import KMeans from sklearn\n",
    "____\n",
    "\n",
    "# Intantiate a KMeans object which will generate 10 clusters.\n",
    "# Use random_state=123, all other arguments as their default.\n",
    "# Store as 'km'.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28. (2pts) Generate Cluster Assignments\n",
    "\n",
    "# Use 'fit_predict' on X_2D to both fit our k-means model and generate cluster assignments.\n",
    "# Store the result as 'cluster_assignments'.\n",
    "____\n",
    "\n",
    "# Print the first 10 cluster assignments\n",
    "# Note: cluster assignment values will be from 0 to 9\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29. (5pts) Plot PCA Representation Colored by Cluster Assignment\n",
    "\n",
    "# Create the same plot as we did above, again using the X_2D data,\n",
    "#   this time color the data by cluster instead of class label.\n",
    "# Use s=80 (size), alpha=0.8, label='cluster '+str(i)\n",
    "\n",
    "# Note that the cluster assignments should look very similar to the class assignments in the plot above, \n",
    "#   meaning that the data is highly clustered even in this 2D space.\n",
    "# Also note that the colors may be different from the plot above, since there is no ordering to the clusters.\n",
    "\n",
    "# Create a single figure and axis of size8,8 using plt.subplots.\n",
    "____\n",
    "\n",
    "# For each cluster (0 to 9):\n",
    "for cluster in range(10):\n",
    "    # Select the rows from X_2D in that cluster using cluster_assignment.\n",
    "    # Store as X_subset.\n",
    "    ____\n",
    "    \n",
    "    # Add a scatter plot of X_subset to the figure using ax.scatter()\n",
    "    #     with s=80, alpha=0.8 and label='cluster' + str(cluster)\n",
    "    ____\n",
    "    \n",
    "    # Also plot each the cluster centers as x's using ax.plot()\n",
    "    #    with marker='x', c='k', ms=20, label=None\n",
    "    #    Cluster centers are stored as a list of tuples in km.cluster_centers_.\n",
    "    ____\n",
    "        \n",
    "# Add a legend to the plot.\n",
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-f19",
   "language": "python",
   "name": "eods-f19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
