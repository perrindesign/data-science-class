<!DOCTYPE html>
<html>
  <head>
    <title>Hypothesis Testing</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Garamond);
      @import url(https://fonts.googleapis.com/css?family=Muli:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);
    </style>
    <link rel="stylesheet" href="../style.css">
  </head>
  <body>
    <textarea id="source">

class: center, middle

Elements of Data Science - F2019

# Hypothesis Testing

---
# Hypothesis Testing

--
count:false
- Random Sampling
--
count:false
- Confidence Intervals
--
count:false
- A/B Tests
--
count:false
- Hypothesis Testing
--
count:false
- Permutation Tests
--
count:false
- p-values
--
count:false
- Calculating Power
--
count:false
- Multi-Armed Bandit

---
# Questions and more questions

--
count:false
- Have web conversions gone up?
--
count:false
- Have stock prices changed?
--
count:false
- Which ad generates more sales?
--
count:false
- Which headline generates more clicks?
--
count:false
- Did the number of likes change?

---
#Population Distributions and Sampling

<br/>
--
count:false
- **The World :: Ground Truth**
    - Ex: How taxi rides work

<br/>
--
count:false
- **Our Data :: An Experiment**
    - Ex: The taxi rides we saw in Jan 2017

---
#Population Dists. and Sampling
<br>
--
count:false
- **Population Distribution:** The actual distribution out in world
    - Ex: Actual distribution of taxi trip length

--
count:false
- **Random Sample:** Our observations of the true population distrution 
--
count:false
    - We hope this does not differ systematically from the true distribution
--
count:false
    - Ex: The taxi trip lengths recorded in Jan 2017

--
count:false
- **Sample Size (n):** The number of observations, the larger the better
    - Ex: We saw 10,000 trips

---
#Population Dists and Sampling
<br>
--
count:false
- **Sample Statistic:** eg. mean, median, standard deviation
    - Ex: We're interested in mean trip length

--
count:false
- **Sampling Distribution:** Distribution of the sample statistic
    - Ex: How is mean trip length distributed?

--
count:false
- **Population Mean vs. Sample Mean:**  $\mu$  vs.  $\bar{x}$
    - Ex: The true mean trip length vs the one we observed

--
count:false
- **Population Std. Dev. vs Sample Std. Dev.:**  $\sigma$  vs.  $s$
    - Ex: The true spread of trip length vs the one we observed


---
# Things To Know First

- sample size
- shape
- location (central tendencies)
- spread


---
# Taxi Example

```python
df = pd.read_csv('../data/yellow_tripdata_2017-01_subset10000rows.csv')

# imagine this is our population distribution
trip_distance = df.trip_distance.dropna().iloc[:1000]
```

---
# Sample of Taxi Data
.smaller[
```python
# sample size
n = 50

# take a sample from the population
idx = np.random.permutation(len(trip_distance))

sample_idx = idx[:n]

sample = trip_distance.iloc[sample_idx]
sample.describe()
```]
.smaller[
```
count    50.000000
mean      2.619600
std       3.363321
min       0.200000
25%       0.957500
50%       1.450000
75%       2.475000
max      15.940000
Name: trip_distance, dtype: float64
```]

---
# Plot Sample

```python
fig,ax = plt.subplots(1,2,figsize=(12,4))
sns.distplot(sample, kde=False, rug=True, ax=ax[0]);
sns.boxplot(sample, ax=ax[1]);
```
.center[![:scale 100%](images/tripdistance_distplot.png)]


---
# Define the Sample Statistic

```python
xbar = sample.mean()
f'sample mean: {xbar:0.2f}'
```
```
'sample mean: 2.62'
```

--
count:false
- How good of an approximation is our sample statistic?
--
count:false
- Let's take more samples!

---
# Generating Samples

```python
sample_means = []
for i in range(1000):
    idx = np.random.permutation(len(trip_distance))
    sample_means.append(trip_distance.iloc[idx[:n]].mean())
```

---
# Sampling Distribution
.smaller[
```python
# sampling distribution with original statistic
ax = sns.distplot(sample_means, kde=False)
ax.set_xlabel('sample_means');
ax.set_ylabel('frequency');
ax.vlines(xbar,*ax.get_ylim());
```]
.center[![:scale 50%](images/tripdistance_samplemeans_distplot.png)]


---
# Central Limit Theorem

<br>
--
count:false
If all samples are randomly drawn from the same sample population:

<br>
--
count:false
For reasonably large samples (usually $n \ge 30$), the distribution of sample mean $\bar{x}$ is normal regardless of the distribution of $X$.

<br>
--
count:false
The sampling distribution of $\bar{x}$ becomes approximately normal as the the sample size $n$ gets large.

<br>
Ex: $X$ = trip_distance, $\bar{x}$ = mean trip_distance, $n$ = 50

---
# What is Normal?

<br>
--
count:false
- distribution defined by mean ($\mu$) and standard deviation ($\sigma$)

<br>
--
count:false
- $N(x;\mu,\sigma) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2\sigma}{(x-\mu)}^2}$

<br>
--
count:false
- **PDF** (Probability Density Function): function of a continuous random variable that provides a relative likelihood of seeing a particular sample of a random variable.


<br>
---
# Plotting a Standard Normal

.smaller[
- Standard Normal: $\mu = 0, \sigma = 1$
- Often referred to as $Z$
]

--
count:false
.smallest[
```python
x = np.random.normal(0,1,size=100000)
ax = sns.distplot(x);
ax.set_xlabel('x');ax.set_ylabel('N(x;0,1)')
ax.vlines([-1,1],0,sp.stats.norm.pdf(1), colors='k');
ax.vlines([-2,2],0,sp.stats.norm.pdf(2), colors='r');
```]
.center[![:scale 40%](images/normal_distplot.png)]


---
# Properties of a Standard Normal

.center[
![:scale 60%](images/standard-normal-distribution.jpg)]

.smallest[
from http://www.statisticshowto.com/wp-content/uploads/2013/09/standard-normal-distribution.jpg]

---
# Confidence Intervals

- Typically we only have one sample

--
count:false
.smaller[
```python
# treat all observations as our sample
n = len(trip_distance)
n
```
```
1000
```]
--
count:false
.smaller[
```python
x_bar = trip_distance.mean()
print(f'sample mean: {x_bar:0.4f}')
```
```
sample mean: 2.8324
```]

--
count:false
- What is the spread of our sample statistic?
--
count:false
- What other values might it take?

---
# Generate Confidence Intervals

## Bootstrap Confidence Interval: sampling with replacement

--
count:false
1. draw a random sample of size *n* from the data
--
count:false
2. record the sample statistic from this random sample
--
count:false
3. repeat 1 and 2 many times
--
count:false
4. for an $\alpha\%$ conf. int., trim off $\frac{1}{2}(1-\frac{\alpha}{100})$ of the data from both ends
--
count:false
6. those trim points are the endpoints of the the $\alpha\%$ bootstrap confidence interval

---
# Bootstrap Sampling

Sampling with replacement

--
count:false
```python
def generate_bootstrap(X, size=None):
    # get the length of the data
    len_X = len(X)

    # default size of bootstrap is len(X)
    if not size:
        size = len_X

    # resample from X size times
    sample = []
    for i in range(size):
        idx = np.random.randint(len_X)
        sample.append(X[idx])

    return sample
```

---
# Generating Bootstrap Samples
```python
# 3. repeat 1 and 2 many times
num_iterations = 500

bootstrap_means = []
for i in range(num_iterations):

    # 1. draw a random sample of size *n* from the data
    bootstrap = generate_bootstrap(trip_distance.values)

    # 2. record the sample statistic from this random sample
    bootstrap_means.append(np.mean(bootstrap))

bootstrap_means = np.array(bootstrap_means)
```

---
# Calculate Conf Intervals

.smaller[
```python
# 4. for an 95% conf. int., trim off .5*(1-(.95/100)) of the data from both ends
```
]
.smaller[
```python
# sort the statistics
bootstrap_means.sort()

# calculate where to trim
trim = ((1-.95) / 2) * num_iterations

# find the closest integer
trim = int(np.round(trim))
trim
```]
.smaller[
```
13
```]

.smaller[
```python
# 5. those trim points are the endpoints of the the  \alpha%  bootstrap conf int
ci = bootstrap_means[[trim,-trim]]
ci
```]
.smaller[
```
array([2.62839, 3.04472])
```]

---
# Plotting Distribution With CIs

.smaller[
```python
ax = sns.distplot(bootstrap_means)
ax.set_xlabel('bootstrap sample means')
ax.vlines(trip_distance.mean(), \*ax.get_ylim(), color='r');
ax.vlines(ci, *ax.get_ylim(), color='b');
```]
.center[![:scale 50%](images/tripdistance_bootstrap_distplot_withconfints.png)]

---
# Plot Measure with CIs

```python
sns.barplot(trip_distance,
            estimator=np.mean, #default
            ci=95,             #default
            n_boot=100,        #default
            orient='v',
            color='c',
           );
```
.center[![](images/tripdistance_bootstrap_bar_withconfints.png)]


---
# Interpreting CIs
<br>

--
count:false
Tells us something about the **variablity** of this statistic.

--
count:false
Tells us how **confident** we should be that our parameter lies in the interval.

--
count:false
It does **not** tell us "the probability the true parameter value lies within that interval".

--
count:false
> If confidence intervals are constructed using a given confidence level from an infinite number of independent sample statistics, the proportion of those intervals that contain the true value of the parameter will be equal to the confidence level.

---
class:middle

# Questions re CIs?

---
# A/B Tests
<br>

--
count:false
##Do one of two treatments produce superior results?


--
count:false
- testing two prices to determine which generates more profit
 

--
count:false
- testing two web headlines to determine which produces more clicks


--
count:false
- testing two advertisements to see which produces more conversions

<br>
--
count:false
##Often Used Test Statistics
--
count:false
- difference in means
--
count:false
- difference in counts

---
# Hypothesis Testing


--
count:false
- Ex: Does one webpage lead to more sales than another?


--
count:false
- **Null Hypothesis:** $H_0$
    - the thing we're observing is happening due to random chance
    - Ex: A difference in sales is just random


--
count:false
- **Alternative Hypothesis:** $H_1$
    - the thing we're observing is happening **not** due to random chance
    - Ex: A difference in sales is not just random


--
count:false
- **Experiment**: given data, do we **accept or reject $H_0$**?
    - Ex: if we collect sales can we say that a difference between the two pages isn't random?

---
# Errors in Hypothesis Tests
.center[![:scale 80%](images/TypeI_TypeII.jpeg)]
.smallest[
from https://analyticsdemystified.com/analytics-strategy/type-i-vs-type-ii-errors-in-customer-data-management/]
---

# Errors in Hypothesis Tests
.center[![](images/Type-I-and-II-errors_pregnant.jpg)]

.smallest[
from https://flowingdata.com/2014/05/09/type-i-and-ii-errors-simplified/]

---
# Significance and Power

<br>
--
count:false
- $p\left(\text{reject } H_0 \mid H_0 \text{ true}\right)$ = significance of test
    - Probablity of saying things aren't by chance when they are

<br>
--
count:false
- $p\left(\text{reject } H_0 \mid H_1 \text{ true}\right)$ = power of test
    - Probability of saying things aren't by chance when they aren't
 
---
# Ex: Webpages and Sales

--
count:false
- **Question:** Which webpage leads to more sales?

    - Potential Issue: what if sales are large but infrequent?
    

--
count:false
- **Proxy Variable**: stand in for true value of interest

    - Ex: Assume 'time on page' is correlated with sales

---
# Ex: Webpages and Sales

--
count:false
.smaller[
```python
session_times = pd.read_csv('../data/web_page_data.csv')
session_times.info()
```
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 36 entries, 0 to 35
Data columns (total 2 columns):
Page    36 non-null object
Time    36 non-null float64
dtypes: float64(1), object(1)
memory usage: 704.0+ bytes
```
```python
session_times.head(3)
```
```
	Page	Time
0	Page A	12.6
1	Page B	151.8
2	Page A	21.0
```]

---
# Ex: Plotting Distributions

```python
sns.boxplot(x='Page',y='Time',data=session_times);
```
.center[![:scale 60%](images/pagetime_boxplots.png)]

---
# Ex: Plotting Mean and CIs

```python
sns.barplot(x='Page',y='Time',data=session_times);
```
.center[![:scale 60%](images/pagetime_bar.png)]


---
# Ex: Define Metric

--
count:false
- **Metric:** the measure we're interested in
--
count:false
- Ex: We're interested in a difference of means (Page B - Page A)

--
count:false
.smaller[
```python
mean_a = session_times[session_times.Page == 'Page A'].Time.mean()
mean_b = session_times[session_times.Page == 'Page B'].Time.mean()

observed_metric = mean_b-mean_a
print('observed metric: {:0.2f}'.format(observed_metric))
```
```
observed metric: 21.40
```]


--
count:false
## Is this significant?

- Assuming that $H_0$ is true, is this observation surprising?


---
# Permutation Test

--
count:false
- Recall Central Limit Theorem
> For reasonably large samples, the distribution of sample mean $\bar{x}$ has is normal regardless of the distribution of $X$.

--
count:false
- How do generate additional samples? Resampling!

---
# Permutation Test

--
count:false
1. combine groups together (assume $H_0$ is true)
    - Ex: Ignore Page 
--
count:false
1. permute observations
    - Ex: Reorder Time 
--
count:false
1. create new groups and calcuate statistic (same sizes as originals)
    - Ex: Get set1 of Times of size |PageA| and set2 of size |PageB|
--
count:false
1. calculate metric
    - Ex: mean(set 2) - mean(set 1)
--
count:false
1. repeat many times
--
count:false
1. see where our original observation falls

---
# Ex: Permutation Test

--
count:false
.smaller[
```python
# 0. get group sizes
n_a = sum(session_times.Page == 'Page A')
n_b = sum(session_times.Page == 'Page B')
```]

--
count:false
.smaller[
```python
# 1. combine groups together (assume $H_0$ is true)
samples = session_times.Time
```]

--
count:false
.smaller[
```python
# 2. permute observations
permuted = np.random.permutation(session_times.Time)
```]

--
count:false
.smaller[
```python
# 3. calculate metric
rand_mean_a = permuted[:n_a].mean()
rand_mean_b = permuted[n_a:].mean()
rand_mean_diff = (rand_mean_b - rand_mean_a)
print('{:.2f}'.format(rand_mean_diff))
```
```
65.04
```]

---
# Ex: Permutation Test

--
count:false
.smaller[
```python
# 4. repeat many times
rand_mean_diffs = []
for i in range(10000):
    permuted = np.random.permutation(session_times.Time)
    rand_mean_a = permuted[:n_a].mean()
    rand_mean_b = permuted[n_a:].mean()
    rand_mean_diffs.append(rand_mean_b - rand_mean_a)
```
```
[6.17714285714284,
 0.14285714285712459,
 -21.799999999999983,
 -1.297142857142859,
 -24.4742857142857,
 23.5257142857143,
 0.5542857142856832,
 21.81142857142858,
 30.588571428571427,
 -3.079999999999984]
```]

---
# Ex: Permutation Test

```python
# 5. see where our original observation falls
ax = sns.distplot(rand_mean_diffs, norm_hist=False, kde=False)
ax.set_xlabel('random mean differences');ax.set_ylabel('frequency');
ax.vlines(observed_metric, *ax.get_ylim(), color='r');
```
.center[![:scale 50%](images/pagetime_permutation_test.png)]


---
#Normalization: z-score

- Convert our distribution to an approximation of standard normal

1. shift mean to 0
2. standard deviation of 1

$\Large z = \frac{x - \bar{x}}{s}$

--
count:false
```python
xbar = np.mean(rand_mean_diffs)
s = np.std(rand_mean_diffs)
```
--
count:false
```python
rand_zscores = (rand_mean_diffs - xbar) / s
```

--
count:false
```python
observed_metric_zscore =  (observed_metric - xbar) / s 
```

---
# Ex: Permutation Test

.smaller[
```python
# 5. see where our original observation falls (normalized)
ax = sns.distplot(rand_zscores, norm_hist=False, kde=False)
ax.set_xlabel('random mean differences normed');ax.set_ylabel('frequency');
ax.vlines(observed_metric_zscore, *ax.get_ylim(), color='r');
```]
.center[![:scale 55%](images/pagetime_permutation_test_normed.png)]


---
# Why Permutation Test?
<br>

--
count:false
- data can be numeric or binary


--
count:false
- sample sizes can be different


--
count:false
- assumptions about normally distributed data are not needed

---
class:middle

# Questions?

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script>
    // Config Remark
    remark.macros['scale'] = function (percentage) {
        var url = this;
        return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };
    config_remark = {
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true,
        ratio: "16:9"
    };
      var slideshow = remark.create(config_remark);

    // Configure MathJax
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] /* removed 'code' entry*/
    }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    </script>
  </body>
</html>
