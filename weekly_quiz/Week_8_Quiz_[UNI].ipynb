{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Quiz\n",
    "\n",
    "## [Name] - [UNI]\n",
    "\n",
    "### Due Sat. Nov. 2, 11:59pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np and pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from data/week8_flowershop_data.csv into dataframe df\n",
    "# Print df.info() to see the number of rows, column names and column datatypes and amount of missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we run df.duplicated() we get a vector of booleans that indicate duplicated rows.\n",
    "# Print the sum over df.duplicated() to get the number of duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use drop_duplicates() to drop the duplicated rows and store back into df.\n",
    "# Check the entire row (subset=None) and keep the first duplicate (keep='first')\n",
    "# Print df.shape to confirm rows were dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the info above, we see there are missing values in price.\n",
    "# Before we fill this column, create a new column 'price_missing' in df.\n",
    "# This column should contain integers, 1 for missing, 0 for not missing.\n",
    "# Use .isna() and .astype(int) to create the 'price_missing' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fill the missing values in df.price with the mean of the price column.\n",
    "# Use .fillna() and .mean()\n",
    "# Be sure to either use inplace or store back into the existing price column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the price column using the sklearn StandardScaler\n",
    "\n",
    "# Import StandardScaler from sklearn.\n",
    "# Use either fit() and transform() or fit_transform() on the price column only.\n",
    "# NOTE: fit_transform requires a 2D matrix. Use df[['price']] to pass a dataframe instead of a series.\n",
    "# Store the transformed values into a new column 'price_scaled' in df.\n",
    "# Call describe on price and price_scaled columns and note the means and standard deviations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are also missing values in favorite flower.\n",
    "# Since 'favorite_flower' is categorical, let's treat missing as another category.\n",
    "# Fill the empty values in favorite_flower with the string 'MISSING'.\n",
    "# Be sure to either use inplace or store back into the existing favorite_flower column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we have no missing data.\n",
    "# Use .isna().sum().sum() to print the number of missing values in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the categorical feature favorite_flower using pd.get_dummies().\n",
    "# Use prefix='favorite_flower' to add a prefix to each column name.\n",
    "# pd.get_dummies creates a new dataframe, so save the result of pd.get_dummies to df_flower.\n",
    "# Print out the first 3 rows of df_flower to see the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL!\n",
    "\n",
    "# We now need to combine our original dataframe df and this new df_flower \n",
    "# We have not discussed how to do this yet in class, but if you're interested, feel free to try.\n",
    "# We can use the .join() command here as both dataframes share the same index.\n",
    "# For info on join see: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-f19",
   "language": "python",
   "name": "eods-f19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
